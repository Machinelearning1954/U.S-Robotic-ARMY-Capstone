{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Collection\n",
    "\n",
    "This notebook outlines the data collection process for the Autonomous Military Vehicle Recognition and Tactical AI System capstone project. The goal of this step is to collect the necessary data for training and evaluating the computer vision model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Setup and Dependencies\n",
    "\n",
    "First, we need to set up the environment and install the necessary libraries. The primary dependency for this step is the Kaggle API, which we will use to download the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kaggle API Authentication\n",
    "\n",
    "To use the Kaggle API, you need to authenticate with your Kaggle account. You can do this by placing your `kaggle.json` API token in the root directory of this project.\n",
    "\n",
    "1. Go to your Kaggle account page.\n",
    "2. Click on \"Create New API Token\".\n",
    "3. Place the downloaded `kaggle.json` file in the root of this project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Datasets\n",
    "\n",
    "We will now download the selected datasets using the `download_datasets.sh` script. This script automates the process of downloading and extracting the datasets into the `data/raw` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ../scripts/download_datasets.sh\n",
    "!../scripts/download_datasets.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Dataset Contents\n",
    "\n",
    "After the download is complete, we can verify that the datasets have been downloaded and extracted correctly. We will list the contents of the `data/raw` directory to ensure that the dataset files are in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ../data/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "With the datasets downloaded, the next step in the project is to perform exploratory data analysis (EDA) to understand the data distribution, image characteristics, and annotation quality. This will be covered in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

